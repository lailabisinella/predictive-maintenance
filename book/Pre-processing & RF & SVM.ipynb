{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb394079-72dd-4a23-95d6-2458c0b8ff2e",
   "metadata": {},
   "source": [
    "# Pre-processing & RF & SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a9bc54-4cc9-4b36-888d-d325eef410cd",
   "metadata": {},
   "source": [
    "This notebook objective is to train, test and evaluate the performance of a Random Forest (RF) and a Support Vector Machine (SVM) model for predicting future `alert_11` values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18cc15d-3282-4524-97b8-8c685e8ad7cc",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3170bf71-f435-422e-bfd3-4b0ec3cf3af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet('./../data/dataset.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c61a804e-d44b-470c-b97d-8a4bac4a2b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(679045, 17)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the dataset has been imported correctly\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753d6b30-d0a1-45d6-9b6f-6ecd23162eb3",
   "metadata": {},
   "source": [
    "## Pre-processing steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c609f677-6039-4342-90c8-1b72a4b4315b",
   "metadata": {},
   "source": [
    "### Dataset optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce45a5e4-542b-4d11-8254-b2c520dabb46",
   "metadata": {},
   "source": [
    "The dataset has previously been utilised in a predictive maintenance study (*docs/introduction_paper*). In fact, it was retrieved directly from the GitHub repository associated with that study. To fully understand the dataset, it is essential to refer to the corresponding research paper, which indicates that the data has already undergone pre-processing. The paper states:  \n",
    "\n",
    "> Depending on the changes detected by sensors, the irregular sampling time is addressed by resampling the time series with a frequency of 5 seconds, which gives a good trade-off between memory occupation and signal resolution. Missing values are filled in using the last available observation because the absence of new measurements indicates no change in the recorded value.  \n",
    "\n",
    "Additionally, it highlights the original presence of more than one **alert feature**. However, due to the following reasons, only `alert_11` is kept in the dataset:  \n",
    "\n",
    "> Figure 1 presents the distribution of the alert codes most relevant according to the manufacturer. Most of them are rare (i.e., are observed less than 10 times), and alerts 11 (platform motor inverter protection) and 34 (machine in emergency condition) are the most common ones. Alert 34 is thrown when the operator presses an emergency button. However, this occurrence heavily depends on human behavior because the operators often use the emergency button as a quick way to turn the machine off, as confirmed by the plant manager. For this reason, alert 34 is discarded, and the prediction task focuses only on alert 11.  \n",
    "\n",
    "Furthermore, an important insight from the paper is that `session_counter` and `time_to_failure` were not part of the original machine-generated dataset. Instead, they are engineered features introduced by the researchers, with their implementations outlined in the paper through pseudo-code (`session_counter`) and a brief description (`time_to_failure`):  \n",
    "\n",
    "> Intuitively, a session start time is introduced when at least one motion variable increases its value, and a session end time is created when all motion variables have decreased their value in the last ten minutes. Algorithm 1 specifies how sessions are defined.\n",
    "\n",
    "> After pre-processing, it is possible to compute the distance of each data sample within a work session to the successive alert, i.e., the Time To Failure\n",
    "(TTF).\n",
    "\n",
    "Therefore, based on these pieces of information, it is evident that both `time_to_failure` and `session_counter` are not relevant to the classification task, since they were generated by the researchers. Consequently, these features are removed in this section to ensure a closer real-world scenario analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b0a04c5-45fd-4992-b9bf-59a04d76807d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['session_counter', 'time_to_failure'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31978091-abaf-4a28-9fcb-d393588b8ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Flag roping</th>\n",
       "      <th>Platform Position [°]</th>\n",
       "      <th>Platform Motor frequency [HZ]</th>\n",
       "      <th>Temperature platform drive [°C]</th>\n",
       "      <th>Temperature slave drive [°C]</th>\n",
       "      <th>Temperature hoist drive [°C]</th>\n",
       "      <th>Tensione totale film [%]</th>\n",
       "      <th>Current speed cart [%]</th>\n",
       "      <th>Platform motor speed [%]</th>\n",
       "      <th>Lifting motor speed [RPM]</th>\n",
       "      <th>Platform rotation speed [RPM]</th>\n",
       "      <th>Slave rotation speed [M/MIN]</th>\n",
       "      <th>Lifting speed rotation [M/MIN]</th>\n",
       "      <th>alert_11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-06-07 04:14:30.742</td>\n",
       "      <td>31.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>5200.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-06-07 04:14:35.742</td>\n",
       "      <td>31.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>5200.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-06-07 04:14:40.742</td>\n",
       "      <td>31.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>5200.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-06-07 04:14:45.742</td>\n",
       "      <td>31.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>5200.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-06-07 04:14:50.742</td>\n",
       "      <td>31.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>5200.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Timestamp  Flag roping  Platform Position [°]  \\\n",
       "0 2021-06-07 04:14:30.742         31.0                  115.0   \n",
       "1 2021-06-07 04:14:35.742         31.0                  115.0   \n",
       "2 2021-06-07 04:14:40.742         31.0                  115.0   \n",
       "3 2021-06-07 04:14:45.742         31.0                  115.0   \n",
       "4 2021-06-07 04:14:50.742         31.0                  115.0   \n",
       "\n",
       "   Platform Motor frequency [HZ]  Temperature platform drive [°C]  \\\n",
       "0                         5200.0                             18.0   \n",
       "1                         5200.0                             18.0   \n",
       "2                         5200.0                             18.0   \n",
       "3                         5200.0                             18.0   \n",
       "4                         5200.0                             18.0   \n",
       "\n",
       "   Temperature slave drive [°C]  Temperature hoist drive [°C]  \\\n",
       "0                          22.0                          18.0   \n",
       "1                          22.0                          18.0   \n",
       "2                          22.0                          18.0   \n",
       "3                          22.0                          18.0   \n",
       "4                          22.0                          18.0   \n",
       "\n",
       "   Tensione totale film [%]  Current speed cart [%]  Platform motor speed [%]  \\\n",
       "0                     181.0                     0.0                     100.0   \n",
       "1                     181.0                     0.0                     100.0   \n",
       "2                     181.0                     0.0                     100.0   \n",
       "3                     181.0                     0.0                     100.0   \n",
       "4                     181.0                     0.0                     100.0   \n",
       "\n",
       "   Lifting motor speed [RPM]  Platform rotation speed [RPM]  \\\n",
       "0                        0.0                           84.0   \n",
       "1                        0.0                           84.0   \n",
       "2                        0.0                           84.0   \n",
       "3                        0.0                           84.0   \n",
       "4                        0.0                           84.0   \n",
       "\n",
       "   Slave rotation speed [M/MIN]  Lifting speed rotation [M/MIN]  alert_11  \n",
       "0                         116.0                             0.0       0.0  \n",
       "1                         116.0                             0.0       0.0  \n",
       "2                         116.0                             0.0       0.0  \n",
       "3                         116.0                             0.0       0.0  \n",
       "4                         116.0                             0.0       0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the dataset to ensure the columns have been removed\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d96e21-636e-4c0f-be65-0724e9cc4fc2",
   "metadata": {},
   "source": [
    "As is common in most time-series datasets, the `Timestamp` column must be set as the index of the dataset. This allows for efficient time-based operations, such as resampling, sliding window calculations, and trend analysis, while preserving the chronological structure of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bc23f7f-c381-424b-a9ee-3c8bdb86e847",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('Timestamp', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88cd5111-517c-4b41-8055-ceb8f9dd94c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Timestamp'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if Timestamp has become the index of the dataset\n",
    "df.index.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fb645f-f3b9-410b-a6c8-b3f01e892032",
   "metadata": {},
   "source": [
    "### Features extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7090b9cc-b16c-4d84-b11d-bcf280bf46c3",
   "metadata": {},
   "source": [
    "In this section, the label `y` and the features `X` for the models are defined, with `alert_11` serving as the target variable (`y`) and all other columns being designated as features (`X`). This decision is based on the fact that `alert_11` represents the primary event of interest, aligning with the original study’s objective. Moreover, by including all other columns as features, the models can leverage the full range of available data to identify patterns and relationships that may contribute in predicting `alert_11`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cc31d39-dd4d-4f50-a1b1-ba0d7727e14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Label (shape=(1,)): ['alert_11']\n",
      "-> Features (shape=(13,)): ['Current speed cart [%]' 'Flag roping' 'Lifting motor speed [RPM]'\n",
      " 'Lifting speed rotation [M/MIN]' 'Platform Motor frequency [HZ]'\n",
      " 'Platform Position [°]' 'Platform motor speed [%]'\n",
      " 'Platform rotation speed [RPM]' 'Slave rotation speed [M/MIN]'\n",
      " 'Temperature hoist drive [°C]' 'Temperature platform drive [°C]'\n",
      " 'Temperature slave drive [°C]' 'Tensione totale film [%]']\n"
     ]
    }
   ],
   "source": [
    "# State the label and the features\n",
    "import numpy as np\n",
    "\n",
    "label = np.array(['alert_11'])\n",
    "features = np.array(df.columns.difference(label))\n",
    "\n",
    "print(f\"-> Label (shape={label.shape}): {label}\")\n",
    "print(f\"-> Features (shape={features.shape}): {features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a86d5c3e-2b1c-408d-8906-3ee7a7efaab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> X (shape=(679045, 13))\n",
      "-> y (shape=(679045, 1))\n"
     ]
    }
   ],
   "source": [
    "# Extract and assign the label and the features, X and y\n",
    "X = df[features]\n",
    "y = df[label]\n",
    "\n",
    "print(f\"-> X (shape={X.shape})\")\n",
    "print(f\"-> y (shape={y.shape})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061689bf-1bf0-447c-ad3b-209193404058",
   "metadata": {},
   "source": [
    "### Sliding window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776db7a0-72dd-4833-9f4f-b31162f6ddad",
   "metadata": {},
   "source": [
    "Creating sliding windows as a pre-processing step is essential for capturing temporal dependencies in the dataset, allowing the models to analyse sequences of past sensor readings rather than isolated time points. \n",
    "Since machine failures and alerts often develop gradually, a single timestamp may not provide enough context for accurate predictions. However, by structuring the data into overlapping time windows, the model can learn meaningful trends and relationships that contribute to the occurrence of `alert_11`. \n",
    "This approach mimics real-world decision-making, where operators and automated systems consider historical data before identifying potential issues. \n",
    "Additionally, sliding windows help handle lag effects, ensuring that early warning signs (such as changes in temperature, speed, or vibrations) are accounted for. Furthermore, this method prevents data leakage by ensuring that predictions rely only on past information, making the model more robust for real-world deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da8b7171-6e07-4b39-9c09-9680255d68fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the label and features for the window\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a2f4917-3391-4816-8fb2-f34bba3c5e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the numpy library for numerical operations, particularly with arrays\n",
    "import numpy as np\n",
    "\n",
    "def window(X_data, y_data, width: int, shift: int):\n",
    "    \n",
    "    # Initialise empty lists to store the generated windows\n",
    "    X_wins, y_wins = [], []\n",
    "\n",
    "    # Loop through each index and corresponding (X, y) pair in the data\n",
    "    for index, (X, y) in enumerate(zip(X_data, y_data)):\n",
    "\n",
    "        # Check if there is enough data remaining to create a full window plus the prediction shift\n",
    "        if (index + width + shift) <= X_data.shape[0]:\n",
    "\n",
    "            # Define a slice object that captures the future range where we want to predict\n",
    "            window = slice((index + width), (index + width + shift))\n",
    "\n",
    "            # Create an input window: take 'width' number of X_data points starting from 'index'\n",
    "            X_wins.append(X_data[index: index + width])\n",
    "\n",
    "            # For labels (y), grab the values in the 'shift' future window\n",
    "            y_values_shift = y_data[window]\n",
    "            \n",
    "            # If any of the future y values is '1', label the window as 1 otherwise, label it as 0\n",
    "            y_wins.append(int(np.any(y_values_shift == 1)))\n",
    "\n",
    "    # Convert the lists of windows into numpy arrays for efficient processing\n",
    "    X_wins = np.array(X_wins)\n",
    "    y_wins = np.array(y_wins)\n",
    "\n",
    "    # Return the X windows reshaped as (number of samples, flattened window) and the corresponding y labels\n",
    "    return X_wins.reshape(X_wins.shape[0], -1), y_wins.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c9b467a-5ccf-4e6c-825a-700ca9d5ec8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# State the variables and the size of the window\n",
    "X_wins, y_wins = window(X, y, width=120, shift=180)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8523428f-4291-4f53-8839-71f1ba293029",
   "metadata": {},
   "source": [
    "### Random Under Sampler (RUS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ac5eea-531d-4065-8a3e-bc3af95f0934",
   "metadata": {},
   "source": [
    "As stated in the paper:  \n",
    "\n",
    "> Alerts are anomalies and thus, by definition, rarer than normal behaviors.  \n",
    "\n",
    "This observation is supported by the exploratory data analysis (EDA) conducted in this study, which confirms that the dataset is highly imbalanced. Specifically, `alert_11` consists of **677,652 instances of 0s** and only **1,393 instances of 1s**, corresponding to **99.8%** and **0.2%** of the dataset, respectively.  \n",
    "\n",
    "This class imbalance issue was also acknowledged in the paper. Given that our study shares the same objective, **Random Under-Sampling (RUS)** is considered an appropriate method for balancing the dataset. As described in the paper:  \n",
    "\n",
    "> The algorithm (RUS) randomly selects and removes observations from the majority class until it achieves the desired equilibrium between the two classes. In the case of the wrapping machine, RUS is applied separately on each train set (comprising 4 folds) and test set (1 fold) for each combination of RW and PW sizes, to prevent the presence of similar data in the train and test sets (i.e., partially overlapping data).  \n",
    "\n",
    "By employing RUS to the **sliding window** data, we ensure that the models are trained on a more balanced dataset, reducing the bias toward the majority class (`alert_11 = 0`) and improving its ability to correctly predict rare alert occurrences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d08eb9a0-40c9-415a-86fd-571a9d592aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([3324, 3324]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "\n",
    "X_res, y_res = rus.fit_resample(X_wins, y_wins)\n",
    "np.unique(y_res, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fc74a6-4f1e-4b29-80b8-59bdb9c87b0d",
   "metadata": {},
   "source": [
    "After applying Random Under-Sampling (RUS), it is not usually expected that the number of positive cases (1s) would exceed what was originally present in the raw dataset (1,393). However, in this case, the result is correct because the windowing process alters the distribution of labels. \n",
    "\n",
    "Initially, the dataset contained **677,652 instances of 0** and only **1,393 instances of 1** for the `alert_11` feature. However, when the **windowing function** is applied, each window is labelled as 1 if any future value within the shift period is 1. As a result, a single occurrence of 1 in the original data can lead to multiple windows being labelled as 1. Therefore, after windowing, the number of windows labelled as 1 becomes much larger than the original 1,393. \n",
    "\n",
    "**Random Under-Sampling** then balances the two classes by reducing the majority class (0) down to match the number of minority instances (1) found after windowing, without creating any new 1s. This is why there is a result of 3,324 instances for both 0 and 1 after resampling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cedda7-e288-48ed-b7ae-013bdccf7573",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3812de4e-d69b-49cb-ad08-3f10774e8265",
   "metadata": {},
   "source": [
    "To establish the credibility of this study, three models (two in this notebook, another in the *Pre-processing & LSTM*) from the original research are implemented. However, it is important to emphasise that this study is not merely a replication of the dataset-associated paper. While the objectives and methodological approaches remain the same, the **techniques** and **models** **implementations slightly differ** from the original study.  \n",
    "\n",
    "One key distinction is that the code in this study is designed to be **simpler and more accessible**, making it easier to understand compared to the implementation in the paper’s GitHub repository ([GitHub Repository](https://github.com/nicolopinci/polimi_failure_prediction)). Despite its simplified approach, the effectiveness of this study remains uncompromised, as the results align closely with those presented in the original research.  \n",
    "\n",
    "By incorporating both **traditional machine learning models (RF, SVM)** and **a deep learning approach (LSTM)**, this study provides a comprehensive evaluation of different techniques in predictive maintenance, ensuring a well-rounded assessment of classification performance on the given dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7697d478-96ce-4ad5-98f5-91043136c3cf",
   "metadata": {},
   "source": [
    "Since this is a classification task, all models will be evaluated using **accuracy, precision, recall, and F1-score**, as these metrics provide a comprehensive assessment of a model's performance, particularly in detecting rare alert occurrences.  \n",
    "\n",
    "Additionally, **stratified and non-stratified 5-fold cross-validation** will be used for models' validation. This sightly differs from the original work as, in this work, there is a prefernce in the use of stratified 5-fold cross-validation rather than 5-fold cross-validation.\n",
    "\n",
    "> The validation procedure is also adapted to the characteristics of the different use cases. In the wrapping machine dataset, there are only 13 alarms, which yield ≈500 failure RWs in the whole time series. Thus, the number of failure RWs in the test set would be too small to test adequately the performances. Thus, we adopt a training and evaluation procedure based on k-fold cross-validation (with k = 5).\n",
    "\n",
    "The reason of this choice is that stratified 5-fold cross-validation ensures that each fold maintains the original class distribution, which is especially important for imbalanced datasets. In contrast, standard 5-fold cross-validation may create folds with uneven class ratios, leading to biased model evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dd3a25-a6ff-4b20-a36b-16f9e09cf145",
   "metadata": {},
   "source": [
    "### Random Forest (RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6100cfce-836b-49e5-8134-863c73230810",
   "metadata": {},
   "source": [
    "The code presented below displays two Random Forest (RF) models developed for the same prediction task. The reason for implementing both versions is due to the differences in their results, caused by a small change in the validation approach.\n",
    "\n",
    "The first model uses **Stratified 5-Fold Cross-Validation**, the same technique applied when training and evaluating the SVM and LSTM models. This method worked effectively for those two models, producing results closely aligned with those reported in the original paper. However, this was not the case for the RF model. The results appeared unrealistically high, with an `F1-score` reaching `0.995`, compared to `0.577` reported in the original paper. Such a discrepancy suggests that the model is likely overfitting.\n",
    "\n",
    "To address this, a switch to **standard 5-Fold Cross-Validation** was made, following the original work intrustion, which produced more reliable results. Although the `F1-score` dropped to `0.40`, this outcome is more plausible and preferable to a near-perfect score, which can mask underlying issues. Moreover, the classification report further confirms that the model performs reasonably well overall, but struggles with the minority class, a known limitation in imbalanced datasets, despite the implementation of RUS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77508ba2-2c24-4b40-b61c-57a5a025b25c",
   "metadata": {},
   "source": [
    "#### RF with Stratified 5-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04085907-46ed-4b54-94f3-bdc024b36848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model implementation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff4b7d37-ea4d-48f3-8632-22abd6c69d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Stratified 5-Fold Cross Validation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39ed91a9-b860-4d1a-a191-a50e977fc355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to store metrics for each fold\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1dbfe4b-7510-46d3-a4d4-51be987a0e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform stratified 5-fold cross-validation\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "for train_index, val_index in kf.split(X_res, y_res):\n",
    "    X_train, X_val = X_res[train_index], X_res[val_index]\n",
    "    y_train, y_val = y_res[train_index], y_res[val_index]\n",
    "    \n",
    "    # Train the model\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on validation fold\n",
    "    y_pred_fold = rf_model.predict(X_val)\n",
    "    \n",
    "    # Calculate and store metrics\n",
    "    accuracy_list.append(accuracy_score(y_val, y_pred_fold))\n",
    "    precision_list.append(precision_score(y_val, y_pred_fold))\n",
    "    recall_list.append(recall_score(y_val, y_pred_fold))\n",
    "    f1_list.append(f1_score(y_val, y_pred_fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33c74cc7-8204-4447-9984-f0bfcd01c841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Metrics across 5 folds:\n",
      "Accuracy:  0.9952\n",
      "Precision: 0.9905\n",
      "Recall:    1.0000\n",
      "F1-Score:  0.9952\n"
     ]
    }
   ],
   "source": [
    "# Print mean metrics across the 5 folds\n",
    "import numpy as np\n",
    "\n",
    "print(\"Mean of Metrics across 5 folds:\")\n",
    "print(f\"Accuracy:  {np.mean(accuracy_list):.4f}\")\n",
    "print(f\"Precision: {np.mean(precision_list):.4f}\")\n",
    "print(f\"Recall:    {np.mean(recall_list):.4f}\")\n",
    "print(f\"F1-Score:  {np.mean(f1_list):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5378b18-2329-46d7-a62f-5e7ac01fe3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (based on cross-validated predictions):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00      3324\n",
      "           1       0.99      1.00      1.00      3324\n",
      "\n",
      "    accuracy                           1.00      6648\n",
      "   macro avg       1.00      1.00      1.00      6648\n",
      "weighted avg       1.00      1.00      1.00      6648\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate overall classification report\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = cross_val_predict(rf_model, X_res, y_res, cv=kf)\n",
    "\n",
    "print(\"Classification Report (based on cross-validated predictions):\")\n",
    "print(classification_report(y_res, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792d1b82-2637-4e1f-9383-d84dbda0c8fa",
   "metadata": {},
   "source": [
    "#### RF with 5-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ab35366-6f64-43a7-a8c1-56fa9ea19fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model implementation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c56b516-ec8e-4805-a759-9b79c43f3f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the scoring metrics to evaluate\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1b89925-95fe-41a6-a863-d1f500b335bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement 5-fold-cross-validation on the model\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "cv_results = cross_validate(rf_model, X_res, y_res, cv=5, scoring=scoring, return_estimator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09aa270a-6e3a-493f-81c4-d2745a6ef5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Metrics across 5 folds:\n",
      "Accuracy: 0.6466\n",
      "Precision: 0.9151\n",
      "Recall: 0.3023\n",
      "F1: 0.4034\n"
     ]
    }
   ],
   "source": [
    "# Print mean metrics across folds\n",
    "print(\"Mean of Metrics across 5 folds:\")\n",
    "for metric in scoring:\n",
    "    mean_score = cv_results['test_' + metric].mean()\n",
    "    print(f\"{metric.capitalize()}: {mean_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1073142e-e42b-46b7-844f-5a8d26e58e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model implementation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe276690-4974-48ae-ada4-ff37bd98adff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (based on cross-validated predictions):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.99      0.74      3324\n",
      "           1       0.97      0.30      0.46      3324\n",
      "\n",
      "    accuracy                           0.65      6648\n",
      "   macro avg       0.78      0.65      0.60      6648\n",
      "weighted avg       0.78      0.65      0.60      6648\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get cross-validated predictions to print a classification report\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = cross_val_predict(rf_model, X_res, y_res, cv=5)\n",
    "\n",
    "print(\"Classification Report (based on cross-validated predictions):\")\n",
    "print(classification_report(y_res, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad3f601-2b8a-4dd5-bd62-344be07a41b5",
   "metadata": {},
   "source": [
    "### Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f735e2cf-a497-418b-94b4-9b0071bf6030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform stratified 5-fold-cross-validation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "58e79c9d-2503-46e6-85d9-c94c2a4e699e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model \n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "77da7337-870b-4204-8975-932b615c8986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store metrics and predictions\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "fold_metrics = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2c2185d4-ca76-46c0-975f-9f4296bf929e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Cross-validation loop\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_res, y_res)):\n",
    "\n",
    "    X_train, X_val = X_res[train_idx], X_res[val_idx]\n",
    "    y_train, y_val = y_res[train_idx], y_res[val_idx]\n",
    "\n",
    "    # Fit and predict\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    y_pred = svm_model.predict(X_val)\n",
    "\n",
    "    # Save predictions for final report\n",
    "    all_y_true.extend(y_val)\n",
    "    all_y_pred.extend(y_pred)\n",
    "\n",
    "    # Calculate metrics for the fold\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    fold_metrics.append({\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1': f1\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b5816a62-fbbb-4622-9017-538b17f59573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with fold results\n",
    "metrics_df = pd.DataFrame(fold_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cb204568-ea91-47cc-b881-965473c243d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Metrics across each fold:\n",
      "   Accuracy  Precision    Recall        F1\n",
      "0  0.772932   0.877339  0.634586  0.736475\n",
      "1  0.774436   0.889126  0.627068  0.735450\n",
      "2  0.750376   0.864333  0.593985  0.704100\n",
      "3  0.754703   0.893023  0.578313  0.702011\n",
      "4  0.756208   0.914842  0.565414  0.698885\n"
     ]
    }
   ],
   "source": [
    "# Print fold-by-fold results\n",
    "print(\"Performance Metrics across each fold:\")\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4d7e7f0c-27f5-4f0f-b1a9-7e07e1a07809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Metrics across 5 folds:\n",
      "Accuracy     0.761731\n",
      "Precision    0.887732\n",
      "Recall       0.599873\n",
      "F1           0.715384\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Print average metrics\n",
    "print(\"Mean of Metrics across 5 folds:\")\n",
    "print(metrics_df.mean(numeric_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "23dadbcb-a6f8-4598-a9ab-1619cbf473f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Classification Report (Aggregated across all folds):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6977    0.9236    0.7949      3324\n",
      "           1     0.8870    0.5999    0.7157      3324\n",
      "\n",
      "    accuracy                         0.7617      6648\n",
      "   macro avg     0.7924    0.7617    0.7553      6648\n",
      "weighted avg     0.7924    0.7617    0.7553      6648\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate a final classification report using all predictions\n",
    "print(\"Final Classification Report (Aggregated across all folds):\")\n",
    "print(classification_report(all_y_true, all_y_pred, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "predictive-maintenance",
   "language": "python",
   "name": "predictive-maintenance"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
